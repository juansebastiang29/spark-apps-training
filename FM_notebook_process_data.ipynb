{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%AddDeps org.jsoup jsoup 1.11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import mutable collections\n",
    "import scala.io.Source\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import scala.collection.mutable.Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import jsoup\n",
    "import org.jsoup.Jsoup\n",
    "import org.jsoup.nodes.Element\n",
    "import scala.collection.JavaConversions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import Java utils for gzip decompression\n",
    "// Import Java utils for reading files\n",
    "import java.io.File\n",
    "import java.io.{FileInputStream}\n",
    "import java.util.zip.{GZIPInputStream}\n",
    "import scala.util.Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Generate a list of files\n",
    "var listFiles= new File(\"Data/\")\n",
    "val rows = spark.sparkContext.parallelize(listFiles.listFiles.filter(_.isFile).map(_.toString).toSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Decompression function for each file\n",
    "def decompress(compressed: String) = {\n",
    "    val inputStream = new GZIPInputStream(new FileInputStream(compressed))\n",
    "    scala.io.Source.fromInputStream(inputStream).mkString\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// html object processor\n",
    "object HTML_X {\n",
    "    \n",
    "    def makeDataSet(list_files:org.apache.spark.rdd.RDD[String]) = {\n",
    "\n",
    "        val mytitles:ListBuffer[String] = ListBuffer.empty[String]\n",
    "        val mydomains:ListBuffer[String] = ListBuffer.empty[String]\n",
    "//         val rowsSampleList = list_files.collect().toList\n",
    "\n",
    "        list_files.collect().foreach(element =>{\n",
    "            try {\n",
    "                mytitles += Jsoup.parse(decompress(compressed = element))\n",
    "                        .getElementsByTag(\"title\").text()\n",
    "                mydomains += element.toString.split(\"_\")(0).split(\"/\")(1)\n",
    "            } catch {\n",
    "                case e: Exception =>{\n",
    "                    println(\"Corrupted file exception %s\".format(element))\n",
    "         }}\n",
    "            \n",
    "\n",
    "        })\n",
    "    //     var rowsDataTitles = mydomains.toList zip mytitles.toList\n",
    "        (mydomains.toList,mytitles.toList).zipped.toSeq.toDF(\"domain\",\"title\")\n",
    "\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor {\n",
    "    \n",
    "    def Remover{\n",
    "        \n",
    "//         remove comments\n",
    "    }\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rowsSample = rows.sample(withReplacement=false,\n",
    "                             fraction = 0.3, \n",
    "                             seed = 29)\n",
    "rowsSample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val article_html = Jsoup.parse(decompress(compressed = rowsSample.takeSample(withReplacement = false,\n",
    "                                                                             num = 1, \n",
    "                                                                             seed = 29)(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val links = article_html.select(\"a,h1,h2,p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.util.control.Breaks._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var i = 0\n",
    "for (element <- links){\n",
    "    println(element.toString)\n",
    "    println(element.text())\n",
    "    i = i + 1;\n",
    "    if (i ==50){break}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_html.remove(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var dataTitles = HTML_X.makeDataSet(list_files=rowsSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTitles.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTitles.createTempView(\"hg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTitles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%SQL\n",
    "\n",
    "SELECT domain, COUNT(title) as total_news\n",
    "FROM hg\n",
    "GROUP BY domain\n",
    "ORDER BY total_news DESC\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lit, ltrim, rtrim, rpad, lpad, trim}\n",
    "\n",
    "var titles_d = dataTitles.select(functions.col(\"title\")).take(20)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
